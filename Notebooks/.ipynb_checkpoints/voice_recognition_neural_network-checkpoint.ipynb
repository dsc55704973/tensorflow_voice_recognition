{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Neural Network: Gender Recognition by Voice and Speech Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for reviewing my Jupyter Notebook, which exhibits a neural network model I developed with Tensorflow.  The model is trained on a dataset featuring comprehensive parameters of the human voice (please review section below dedicated to describing the dataset).  Development of the neural network was straight-forward given how lean the dataset actually is (3,168 records, 20 features) and how inherently robust neural network models are.  \n",
    "\n",
    "Essentially, I trained a model here that will predict the gender of a speaker given these 20 voice parameters.  The end result is a model that generated predictions with 98.23% accuracy, and only 14 wrong predictions!  Pretty remarkable.  The steps to execute this model are generalized as follows: \n",
    "###### Step 1: EDA\n",
    "###### Step 2: Pre-Processing\n",
    "###### Step 3: Model Development\n",
    "###### Step 4: Quantify the Trained Model\n",
    "###### Step 5: Make Predictions\n",
    "###### Step 6: Evaluate Test Results\n",
    "\n",
    "There really wasn't much to the EDA step, except that I just took a cursory look at the features.  In the pre-processing step, I used MinMaxScaler and LabelEncoder to scale the X features and to encode the y variable, and of course TrainTestSplit to get the training and test sets (33% default split).  Model development was also simple, as it only required initiating a sequential model, compiling it, and fitting the model to the categorical X training data with 60 epochs.  Quantifying the model simply involved computing loss and accuracy using evaluate().  In the Making Predictions step, I executed such predictions on scaled test dataset, and then converted the probabilities to class labels to view predictions alongside actuals.  The final step of evaluation entailed recomputing loss and accuracy manually by first computing how many false predictions were made, and finally taking a look at a confusion matrix using Scikit-Learn.\n",
    "\n",
    "The last thing I did was simulate saving and loading the model on new data.  For that, I attempted to leverage ChatGPT on generating a new dataset.  Loading the model on this dataset was unsuccessful, as may be predictable, as the fake dataset failed to capture real patterns that were consistent with the original dataset.  Nevertheless, a template now exists for loading in another dataset in order to test the model's effectiveness on new data.\n",
    "\n",
    "I am proud of my work here and am excited to continue to leverage the power of deep learning for other tasks!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Gender\n",
    "Gender Recognition by Voice and Speech Analysis\n",
    "\n",
    "This database was created to identify a voice as male or female, based upon acoustic properties of the voice and speech. The dataset consists of 3,168 recorded voice samples, collected from male and female speakers. The voice samples are pre-processed by acoustic analysis in R using the seewave and tuneR packages, with an analyzed frequency range of 0hz-280hz (human vocal range).\n",
    "\n",
    "## The Dataset\n",
    "The following acoustic properties of each voice are measured and included within the CSV:\n",
    "\n",
    "* meanfreq: mean frequency (in kHz)\n",
    "* sd: standard deviation of frequency\n",
    "* median: median frequency (in kHz)\n",
    "* Q25: first quantile (in kHz)\n",
    "* Q75: third quantile (in kHz)\n",
    "* IQR: interquantile range (in kHz)\n",
    "* skew: skewness (see note in specprop description)\n",
    "* kurt: kurtosis (see note in specprop description)\n",
    "* sp.ent: spectral entropy\n",
    "* sfm: spectral flatness\n",
    "* mode: mode frequency\n",
    "* centroid: frequency centroid (see specprop)\n",
    "* peakf: peak frequency (frequency with highest energy)\n",
    "* meanfun: average of fundamental frequency measured across acoustic signal\n",
    "* minfun: minimum fundamental frequency measured across acoustic signal\n",
    "* maxfun: maximum fundamental frequency measured across acoustic signal\n",
    "* meandom: average of dominant frequency measured across acoustic signal\n",
    "* mindom: minimum of dominant frequency measured across acoustic signal\n",
    "* maxdom: maximum of dominant frequency measured across acoustic signal\n",
    "* dfrange: range of dominant frequency measured across acoustic signal\n",
    "* modindx: modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range\n",
    "* label: male or female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt',\n",
       "       'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun',\n",
       "       'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice = pd.read_csv('../Resources/voice.csv')\n",
    "voice.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86a9e3212f200d21",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 20) (3168,)\n"
     ]
    }
   ],
   "source": [
    "# set features X and predictor y\n",
    "X = voice.drop(\"label\",axis =1)\n",
    "y = voice[\"label\"]\n",
    "\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711a82d9b32c83ff",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 500)\n",
    "\n",
    "# fit X TRAINING SET only with scaler; transform X TRAINING and X TEST sets\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# ENCODE Y sets\n",
    "# Step 1: Label-encode data set with LabelEncoder()\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_encoded_train = label_encoder.transform(y_train)\n",
    "y_encoded_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding using to_categorical()\n",
    "y_train_categorical = to_categorical(y_encoded_train)\n",
    "y_test_categorical = to_categorical(y_encoded_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create neural network model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 100, activation = 'relu', input_dim = 20))\n",
    "model.add(Dense(units = 100, activation = 'relu'))\n",
    "model.add(Dense(units=2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m2,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m202\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,402</span> (48.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,402\u001b[0m (48.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,402</span> (48.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,402\u001b[0m (48.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.8346 - loss: 0.4536\n",
      "Epoch 2/60\n",
      "75/75 - 0s - 511us/step - accuracy: 0.9402 - loss: 0.1913\n",
      "Epoch 3/60\n",
      "75/75 - 0s - 467us/step - accuracy: 0.9634 - loss: 0.1180\n",
      "Epoch 4/60\n",
      "75/75 - 0s - 462us/step - accuracy: 0.9651 - loss: 0.1116\n",
      "Epoch 5/60\n",
      "75/75 - 0s - 460us/step - accuracy: 0.9672 - loss: 0.0946\n",
      "Epoch 6/60\n",
      "75/75 - 0s - 464us/step - accuracy: 0.9718 - loss: 0.0827\n",
      "Epoch 7/60\n",
      "75/75 - 0s - 469us/step - accuracy: 0.9769 - loss: 0.0815\n",
      "Epoch 8/60\n",
      "75/75 - 0s - 465us/step - accuracy: 0.9697 - loss: 0.0835\n",
      "Epoch 9/60\n",
      "75/75 - 0s - 475us/step - accuracy: 0.9752 - loss: 0.0769\n",
      "Epoch 10/60\n",
      "75/75 - 0s - 460us/step - accuracy: 0.9760 - loss: 0.0734\n",
      "Epoch 11/60\n",
      "75/75 - 0s - 465us/step - accuracy: 0.9722 - loss: 0.0847\n",
      "Epoch 12/60\n",
      "75/75 - 0s - 473us/step - accuracy: 0.9769 - loss: 0.0735\n",
      "Epoch 13/60\n",
      "75/75 - 0s - 462us/step - accuracy: 0.9756 - loss: 0.0717\n",
      "Epoch 14/60\n",
      "75/75 - 0s - 467us/step - accuracy: 0.9777 - loss: 0.0692\n",
      "Epoch 15/60\n",
      "75/75 - 0s - 471us/step - accuracy: 0.9777 - loss: 0.0754\n",
      "Epoch 16/60\n",
      "75/75 - 0s - 478us/step - accuracy: 0.9777 - loss: 0.0682\n",
      "Epoch 17/60\n",
      "75/75 - 0s - 465us/step - accuracy: 0.9777 - loss: 0.0666\n",
      "Epoch 18/60\n",
      "75/75 - 0s - 469us/step - accuracy: 0.9760 - loss: 0.0681\n",
      "Epoch 19/60\n",
      "75/75 - 0s - 476us/step - accuracy: 0.9756 - loss: 0.0683\n",
      "Epoch 20/60\n",
      "75/75 - 0s - 466us/step - accuracy: 0.9760 - loss: 0.0725\n",
      "Epoch 21/60\n",
      "75/75 - 0s - 477us/step - accuracy: 0.9764 - loss: 0.0685\n",
      "Epoch 22/60\n",
      "75/75 - 0s - 464us/step - accuracy: 0.9756 - loss: 0.0762\n",
      "Epoch 23/60\n",
      "75/75 - 0s - 475us/step - accuracy: 0.9785 - loss: 0.0686\n",
      "Epoch 24/60\n",
      "75/75 - 0s - 474us/step - accuracy: 0.9794 - loss: 0.0622\n",
      "Epoch 25/60\n",
      "75/75 - 0s - 488us/step - accuracy: 0.9819 - loss: 0.0601\n",
      "Epoch 26/60\n",
      "75/75 - 0s - 468us/step - accuracy: 0.9798 - loss: 0.0592\n",
      "Epoch 27/60\n",
      "75/75 - 0s - 489us/step - accuracy: 0.9811 - loss: 0.0593\n",
      "Epoch 28/60\n",
      "75/75 - 0s - 572us/step - accuracy: 0.9832 - loss: 0.0562\n",
      "Epoch 29/60\n",
      "75/75 - 0s - 478us/step - accuracy: 0.9794 - loss: 0.0580\n",
      "Epoch 30/60\n",
      "75/75 - 0s - 480us/step - accuracy: 0.9819 - loss: 0.0563\n",
      "Epoch 31/60\n",
      "75/75 - 0s - 475us/step - accuracy: 0.9806 - loss: 0.0575\n",
      "Epoch 32/60\n",
      "75/75 - 0s - 486us/step - accuracy: 0.9798 - loss: 0.0557\n",
      "Epoch 33/60\n",
      "75/75 - 0s - 478us/step - accuracy: 0.9785 - loss: 0.0653\n",
      "Epoch 34/60\n",
      "75/75 - 0s - 465us/step - accuracy: 0.9764 - loss: 0.0627\n",
      "Epoch 35/60\n",
      "75/75 - 0s - 479us/step - accuracy: 0.9815 - loss: 0.0528\n",
      "Epoch 36/60\n",
      "75/75 - 0s - 461us/step - accuracy: 0.9811 - loss: 0.0573\n",
      "Epoch 37/60\n",
      "75/75 - 0s - 478us/step - accuracy: 0.9798 - loss: 0.0568\n",
      "Epoch 38/60\n",
      "75/75 - 0s - 491us/step - accuracy: 0.9806 - loss: 0.0528\n",
      "Epoch 39/60\n",
      "75/75 - 0s - 482us/step - accuracy: 0.9815 - loss: 0.0522\n",
      "Epoch 40/60\n",
      "75/75 - 0s - 471us/step - accuracy: 0.9827 - loss: 0.0520\n",
      "Epoch 41/60\n",
      "75/75 - 0s - 483us/step - accuracy: 0.9777 - loss: 0.0600\n",
      "Epoch 42/60\n",
      "75/75 - 0s - 498us/step - accuracy: 0.9811 - loss: 0.0535\n",
      "Epoch 43/60\n",
      "75/75 - 0s - 475us/step - accuracy: 0.9844 - loss: 0.0488\n",
      "Epoch 44/60\n",
      "75/75 - 0s - 491us/step - accuracy: 0.9802 - loss: 0.0506\n",
      "Epoch 45/60\n",
      "75/75 - 0s - 484us/step - accuracy: 0.9794 - loss: 0.0570\n",
      "Epoch 46/60\n",
      "75/75 - 0s - 481us/step - accuracy: 0.9815 - loss: 0.0522\n",
      "Epoch 47/60\n",
      "75/75 - 0s - 497us/step - accuracy: 0.9832 - loss: 0.0488\n",
      "Epoch 48/60\n",
      "75/75 - 0s - 467us/step - accuracy: 0.9819 - loss: 0.0525\n",
      "Epoch 49/60\n",
      "75/75 - 0s - 489us/step - accuracy: 0.9840 - loss: 0.0493\n",
      "Epoch 50/60\n",
      "75/75 - 0s - 480us/step - accuracy: 0.9836 - loss: 0.0490\n",
      "Epoch 51/60\n",
      "75/75 - 0s - 478us/step - accuracy: 0.9836 - loss: 0.0446\n",
      "Epoch 52/60\n",
      "75/75 - 0s - 473us/step - accuracy: 0.9819 - loss: 0.0488\n",
      "Epoch 53/60\n",
      "75/75 - 0s - 473us/step - accuracy: 0.9802 - loss: 0.0497\n",
      "Epoch 54/60\n",
      "75/75 - 0s - 533us/step - accuracy: 0.9857 - loss: 0.0518\n",
      "Epoch 55/60\n",
      "75/75 - 0s - 511us/step - accuracy: 0.9794 - loss: 0.0533\n",
      "Epoch 56/60\n",
      "75/75 - 0s - 498us/step - accuracy: 0.9853 - loss: 0.0432\n",
      "Epoch 57/60\n",
      "75/75 - 0s - 484us/step - accuracy: 0.9848 - loss: 0.0437\n",
      "Epoch 58/60\n",
      "75/75 - 0s - 478us/step - accuracy: 0.9870 - loss: 0.0432\n",
      "Epoch 59/60\n",
      "75/75 - 0s - 487us/step - accuracy: 0.9815 - loss: 0.0467\n",
      "Epoch 60/60\n",
      "75/75 - 0s - 487us/step - accuracy: 0.9840 - loss: 0.0440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x166884110>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train_scaled,\n",
    "          y_train_categorical,\n",
    "          epochs=60,\n",
    "          shuffle=2,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - 2ms/step - accuracy: 0.9798 - loss: 0.0605\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled,\n",
    "    y_test_categorical,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f97eb3e97245187b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step\n"
     ]
    }
   ],
   "source": [
    "# predictions on X_test_scaled\n",
    "predictions = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probabilities to class labels\n",
    "encoded_predictions = predictions.argmax(axis=-1)\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['female' 'female' 'female' 'female' 'female' 'female' 'male' 'female'\n",
      " 'male' 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'female'\n",
      " 'female' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'female' 'female'\n",
      " 'male' 'female' 'male' 'male' 'female' 'female' 'male' 'female' 'male'\n",
      " 'male' 'male' 'female' 'female' 'male' 'female' 'female' 'female' 'male'\n",
      " 'male' 'female' 'female' 'female' 'female' 'male' 'female' 'male'\n",
      " 'female' 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'female'\n",
      " 'male' 'male' 'female' 'female' 'female' 'male' 'female' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'male' 'female' 'male' 'male' 'female'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'male' 'female'\n",
      " 'female' 'male' 'female' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'female' 'female' 'male' 'female' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'female' 'female' 'male' 'male'\n",
      " 'female' 'female' 'female' 'male' 'female' 'male' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'male' 'male' 'male' 'female' 'male' 'female' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'male' 'male'\n",
      " 'female' 'female' 'female' 'female' 'male' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male' 'male' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'female' 'male'\n",
      " 'female' 'male' 'female' 'female' 'female' 'male' 'male' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male' 'female' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'female' 'female' 'female' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'female' 'female' 'female' 'male'\n",
      " 'male' 'female' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'male' 'female' 'male' 'male' 'female' 'female' 'female'\n",
      " 'female' 'male' 'male' 'male' 'male' 'male' 'female' 'female' 'female'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'female'\n",
      " 'female' 'male' 'female' 'female' 'male' 'female' 'female' 'female'\n",
      " 'male' 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'female' 'male' 'female' 'female' 'female' 'female' 'female' 'male'\n",
      " 'female' 'male' 'female' 'female' 'male' 'male' 'male' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'male' 'female' 'female' 'male' 'male'\n",
      " 'male' 'male' 'female' 'male' 'male' 'male' 'female' 'male' 'male'\n",
      " 'female' 'female' 'female' 'male' 'male' 'female' 'female' 'female'\n",
      " 'male' 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'female' 'female'\n",
      " 'male' 'male' 'male' 'female' 'female' 'male' 'female' 'female' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'female' 'male'\n",
      " 'male' 'female' 'male' 'male' 'female' 'female' 'male' 'female' 'male'\n",
      " 'male' 'male' 'female' 'male' 'male' 'female' 'female' 'female' 'female'\n",
      " 'male' 'male' 'female' 'female' 'male' 'male' 'female' 'male' 'female'\n",
      " 'female' 'male' 'female' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'male' 'female' 'male' 'male' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'female' 'male' 'male'\n",
      " 'male' 'male' 'female' 'female' 'male' 'female' 'female' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'male' 'female' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'female'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'female' 'male' 'male' 'female' 'male' 'female' 'female' 'male'\n",
      " 'male' 'female' 'female' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'female' 'male' 'male' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'male' 'female' 'female' 'male' 'female' 'male' 'male'\n",
      " 'female' 'male' 'male' 'male' 'male' 'female' 'female' 'female' 'male'\n",
      " 'male' 'female' 'female' 'male' 'female' 'male' 'female' 'female' 'male'\n",
      " 'male' 'female' 'female' 'male' 'female' 'female' 'male' 'female'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'male' 'female' 'male' 'female' 'female'\n",
      " 'male' 'female' 'female' 'female' 'male' 'female' 'male' 'female'\n",
      " 'female' 'male' 'female' 'female' 'male' 'female' 'female' 'female'\n",
      " 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'female' 'female' 'male' 'male' 'male'\n",
      " 'male' 'female' 'female' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'female'\n",
      " 'male' 'male' 'male' 'male' 'female' 'female' 'female' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'female' 'male'\n",
      " 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'male' 'female'\n",
      " 'female' 'female' 'male' 'female' 'female' 'male' 'female' 'male'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'male' 'male' 'male' 'female' 'male' 'female' 'female' 'female' 'female'\n",
      " 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'female'\n",
      " 'female' 'female' 'male' 'female' 'male' 'female' 'male' 'female' 'male'\n",
      " 'male' 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'female' 'female'\n",
      " 'female' 'female' 'male' 'female' 'female' 'female' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'male' 'male' 'female' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'male' 'female' 'male' 'female' 'female' 'male' 'male'\n",
      " 'male' 'male' 'female' 'male' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'male'\n",
      " 'female' 'male' 'male' 'female' 'male' 'female' 'female' 'male' 'male'\n",
      " 'female' 'male' 'male']\n",
      "Actuals: ['female', 'female', 'female', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'male', 'female', 'male', 'female', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'male', 'male']\n"
     ]
    }
   ],
   "source": [
    "# print predictions vs. actuals\n",
    "print(f'Predictions: {prediction_labels}')\n",
    "print(f'Actuals: {list(y_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 false predictions out of 792 predictions ---> Counter({'male': 399, 'female': 393})\n",
      "Accuracy: 97.98%\n",
      "Check Accuracy: 97.98%\n"
     ]
    }
   ],
   "source": [
    "# loss and accuracy\n",
    "false_predictions = prediction_labels != y_test\n",
    "num_false_predictions = np.sum(false_predictions)\n",
    "totalPredictions = len(prediction_labels)\n",
    "\n",
    "print(f'{num_false_predictions} false predictions out of {totalPredictions} predictions ---> {Counter(prediction_labels)}')\n",
    "print(f'Accuracy: {round((totalPredictions-num_false_predictions) / totalPredictions * 100,2)}%')\n",
    "print(f'Check Accuracy: {round(model_accuracy,4)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1\n",
      " 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0\n",
      " 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0\n",
      " 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1\n",
      " 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 0\n",
      " 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0\n",
      " 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0\n",
      " 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1\n",
      " 1 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0\n",
      " 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0\n",
      " 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 1 0\n",
      " 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0\n",
      " 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0\n",
      " 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1]\n",
      "Actuals: [0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1\n",
      " 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0\n",
      " 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0\n",
      " 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1\n",
      " 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0\n",
      " 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 0\n",
      " 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0\n",
      " 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1\n",
      " 1 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0\n",
      " 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0\n",
      " 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 1 0\n",
      " 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0\n",
      " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0\n",
      " 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_encoded_test,encoded_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(f'Predictions: {encoded_predictions}')\n",
    "print(f'Actuals: {y_encoded_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"voice_gender_nn_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Dataset: Attempt to Execute Predictive Analytics on Alternate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in new dataset (labels randomized in new file)\n",
    "voice2 = pd.read_csv('../Resources/voice2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "X2 = voice2.drop(\"label\",axis =1)\n",
    "y2 = voice2[\"label\"]\n",
    "\n",
    "# train, test, split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2,random_state = 2)\n",
    "\n",
    "# fit X TRAINING SET only with scaler; transform X TRAINING and X TEST sets\n",
    "X_scaler2 = MinMaxScaler().fit(X_train2)\n",
    "X_train_scaled2 = X_scaler2.transform(X_train2)\n",
    "X_test_scaled2 = X_scaler2.transform(X_test2)\n",
    "\n",
    "# ENCODE Y sets\n",
    "# Step 1: Label-encode data set with LabelEncoder()\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train2)\n",
    "y_encoded_train2 = label_encoder.transform(y_train2)\n",
    "y_encoded_test2 = label_encoder.transform(y_test2)\n",
    "\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding using to_categorical()\n",
    "y_train_categorical2 = to_categorical(y_encoded_train2)\n",
    "y_test_categorical2 = to_categorical(y_encoded_test2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = load_model('voice_gender_nn_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step\n"
     ]
    }
   ],
   "source": [
    "# Attempt predictions\n",
    "predictions2 = model.predict(X_test_scaled2)\n",
    "encoded_predictions2 = predictions2.argmax(axis=-1)\n",
    "prediction_labels2 = label_encoder.inverse_transform(encoded_predictions2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392 false predictions out of 792 predictions ---> Counter({'male': 454, 'female': 338})\n",
      "Accuracy: 50.51%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate \n",
    "\n",
    "false_predictions2 = prediction_labels2 != y_test2\n",
    "num_false_predictions2 = np.sum(false_predictions2)\n",
    "totalPredictions2 = len(prediction_labels2)\n",
    "\n",
    "print(f'{num_false_predictions2} false predictions out of {totalPredictions2} predictions ---> {Counter(prediction_labels2)}')\n",
    "print(f'Accuracy: {round((totalPredictions-num_false_predictions2) / totalPredictions2 * 100,2)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAIL (hypothesis: new dataset and unseen patterns are inconsistent with original dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to retrain new model on new data and retry predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m2,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m202\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,402</span> (48.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,402\u001b[0m (48.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,402</span> (48.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,402\u001b[0m (48.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - 3ms/step - accuracy: 0.5328 - loss: 0.6979\n"
     ]
    }
   ],
   "source": [
    "# Create neural network model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 100, activation = 'relu', input_dim = 20))\n",
    "model.add(Dense(units = 100, activation = 'relu'))\n",
    "model.add(Dense(units=2, activation = 'softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model_loss2, model_accuracy2 = model.evaluate(\n",
    "    X_test_scaled2,\n",
    "    y_test_categorical2,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "75/75 - 0s - 4ms/step - accuracy: 0.4949 - loss: 0.6984\n",
      "Epoch 2/60\n",
      "75/75 - 0s - 507us/step - accuracy: 0.5072 - loss: 0.6936\n",
      "Epoch 3/60\n",
      "75/75 - 0s - 483us/step - accuracy: 0.5408 - loss: 0.6893\n",
      "Epoch 4/60\n",
      "75/75 - 0s - 480us/step - accuracy: 0.5412 - loss: 0.6868\n",
      "Epoch 5/60\n",
      "75/75 - 0s - 473us/step - accuracy: 0.5665 - loss: 0.6836\n",
      "Epoch 6/60\n",
      "75/75 - 0s - 471us/step - accuracy: 0.5572 - loss: 0.6816\n",
      "Epoch 7/60\n",
      "75/75 - 0s - 471us/step - accuracy: 0.5821 - loss: 0.6755\n",
      "Epoch 8/60\n",
      "75/75 - 0s - 479us/step - accuracy: 0.5863 - loss: 0.6709\n",
      "Epoch 9/60\n",
      "75/75 - 0s - 480us/step - accuracy: 0.5875 - loss: 0.6689\n",
      "Epoch 10/60\n",
      "75/75 - 0s - 480us/step - accuracy: 0.6132 - loss: 0.6604\n",
      "Epoch 11/60\n",
      "75/75 - 0s - 500us/step - accuracy: 0.6153 - loss: 0.6577\n",
      "Epoch 12/60\n",
      "75/75 - 0s - 478us/step - accuracy: 0.6077 - loss: 0.6522\n",
      "Epoch 13/60\n",
      "75/75 - 0s - 470us/step - accuracy: 0.6326 - loss: 0.6418\n",
      "Epoch 14/60\n",
      "75/75 - 0s - 475us/step - accuracy: 0.6258 - loss: 0.6366\n",
      "Epoch 15/60\n",
      "75/75 - 0s - 470us/step - accuracy: 0.6473 - loss: 0.6277\n",
      "Epoch 16/60\n",
      "75/75 - 0s - 453us/step - accuracy: 0.6578 - loss: 0.6257\n",
      "Epoch 17/60\n",
      "75/75 - 0s - 457us/step - accuracy: 0.6578 - loss: 0.6128\n",
      "Epoch 18/60\n",
      "75/75 - 0s - 469us/step - accuracy: 0.6768 - loss: 0.6045\n",
      "Epoch 19/60\n",
      "75/75 - 0s - 460us/step - accuracy: 0.6700 - loss: 0.5985\n",
      "Epoch 20/60\n",
      "75/75 - 0s - 460us/step - accuracy: 0.6662 - loss: 0.5971\n",
      "Epoch 21/60\n",
      "75/75 - 0s - 453us/step - accuracy: 0.7008 - loss: 0.5835\n",
      "Epoch 22/60\n",
      "75/75 - 0s - 460us/step - accuracy: 0.7016 - loss: 0.5743\n",
      "Epoch 23/60\n",
      "75/75 - 0s - 463us/step - accuracy: 0.7125 - loss: 0.5656\n",
      "Epoch 24/60\n",
      "75/75 - 0s - 456us/step - accuracy: 0.7239 - loss: 0.5570\n",
      "Epoch 25/60\n",
      "75/75 - 0s - 453us/step - accuracy: 0.7281 - loss: 0.5499\n",
      "Epoch 26/60\n",
      "75/75 - 0s - 443us/step - accuracy: 0.7437 - loss: 0.5358\n",
      "Epoch 27/60\n",
      "75/75 - 0s - 458us/step - accuracy: 0.7437 - loss: 0.5247\n",
      "Epoch 28/60\n",
      "75/75 - 0s - 442us/step - accuracy: 0.7496 - loss: 0.5201\n",
      "Epoch 29/60\n",
      "75/75 - 0s - 463us/step - accuracy: 0.7685 - loss: 0.5059\n",
      "Epoch 30/60\n",
      "75/75 - 0s - 459us/step - accuracy: 0.7698 - loss: 0.5031\n",
      "Epoch 31/60\n",
      "75/75 - 0s - 470us/step - accuracy: 0.7828 - loss: 0.4878\n",
      "Epoch 32/60\n",
      "75/75 - 0s - 470us/step - accuracy: 0.7744 - loss: 0.4808\n",
      "Epoch 33/60\n",
      "75/75 - 0s - 479us/step - accuracy: 0.7858 - loss: 0.4761\n",
      "Epoch 34/60\n",
      "75/75 - 0s - 468us/step - accuracy: 0.8047 - loss: 0.4573\n",
      "Epoch 35/60\n",
      "75/75 - 0s - 465us/step - accuracy: 0.8081 - loss: 0.4469\n",
      "Epoch 36/60\n",
      "75/75 - 0s - 456us/step - accuracy: 0.8056 - loss: 0.4408\n",
      "Epoch 37/60\n",
      "75/75 - 0s - 465us/step - accuracy: 0.8131 - loss: 0.4314\n",
      "Epoch 38/60\n",
      "75/75 - 0s - 471us/step - accuracy: 0.8207 - loss: 0.4143\n",
      "Epoch 39/60\n",
      "75/75 - 0s - 475us/step - accuracy: 0.8220 - loss: 0.4159\n",
      "Epoch 40/60\n",
      "75/75 - 0s - 446us/step - accuracy: 0.8371 - loss: 0.4025\n",
      "Epoch 41/60\n",
      "75/75 - 0s - 463us/step - accuracy: 0.8380 - loss: 0.3920\n",
      "Epoch 42/60\n",
      "75/75 - 0s - 468us/step - accuracy: 0.8430 - loss: 0.3867\n",
      "Epoch 43/60\n",
      "75/75 - 0s - 476us/step - accuracy: 0.8514 - loss: 0.3736\n",
      "Epoch 44/60\n",
      "75/75 - 0s - 480us/step - accuracy: 0.8502 - loss: 0.3676\n",
      "Epoch 45/60\n",
      "75/75 - 0s - 533us/step - accuracy: 0.8598 - loss: 0.3535\n",
      "Epoch 46/60\n",
      "75/75 - 0s - 480us/step - accuracy: 0.8712 - loss: 0.3425\n",
      "Epoch 47/60\n",
      "75/75 - 0s - 495us/step - accuracy: 0.8657 - loss: 0.3367\n",
      "Epoch 48/60\n",
      "75/75 - 0s - 484us/step - accuracy: 0.8657 - loss: 0.3401\n",
      "Epoch 49/60\n",
      "75/75 - 0s - 469us/step - accuracy: 0.8624 - loss: 0.3296\n",
      "Epoch 50/60\n",
      "75/75 - 0s - 474us/step - accuracy: 0.8927 - loss: 0.3148\n",
      "Epoch 51/60\n",
      "75/75 - 0s - 475us/step - accuracy: 0.8792 - loss: 0.3077\n",
      "Epoch 52/60\n",
      "75/75 - 0s - 475us/step - accuracy: 0.8994 - loss: 0.2946\n",
      "Epoch 53/60\n",
      "75/75 - 0s - 477us/step - accuracy: 0.8923 - loss: 0.2909\n",
      "Epoch 54/60\n",
      "75/75 - 0s - 478us/step - accuracy: 0.9091 - loss: 0.2795\n",
      "Epoch 55/60\n",
      "75/75 - 0s - 480us/step - accuracy: 0.9074 - loss: 0.2772\n",
      "Epoch 56/60\n",
      "75/75 - 0s - 489us/step - accuracy: 0.9087 - loss: 0.2695\n",
      "Epoch 57/60\n",
      "75/75 - 0s - 477us/step - accuracy: 0.9192 - loss: 0.2602\n",
      "Epoch 58/60\n",
      "75/75 - 0s - 470us/step - accuracy: 0.9196 - loss: 0.2501\n",
      "Epoch 59/60\n",
      "75/75 - 0s - 448us/step - accuracy: 0.9213 - loss: 0.2453\n",
      "Epoch 60/60\n",
      "75/75 - 0s - 453us/step - accuracy: 0.9268 - loss: 0.2384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16729f650>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train_scaled2,\n",
    "          y_train_categorical2,\n",
    "          epochs=60,\n",
    "          shuffle=2,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step\n"
     ]
    }
   ],
   "source": [
    "# Attempt predictions\n",
    "predictions2 = model.predict(X_test_scaled2)\n",
    "encoded_predictions2 = predictions2.argmax(axis=-1)\n",
    "prediction_labels2 = label_encoder.inverse_transform(encoded_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 false predictions out of 792 predictions ---> Counter({'female': 416, 'male': 376})\n",
      "Accuracy: 49.49%\n"
     ]
    }
   ],
   "source": [
    "false_predictions2 = prediction_labels2 != y_test2\n",
    "num_false_predictions2 = np.sum(false_predictions2)\n",
    "totalPredictions2 = len(prediction_labels2)\n",
    "\n",
    "print(f'{num_false_predictions2} false predictions out of {totalPredictions2} predictions ---> {Counter(prediction_labels2)}')\n",
    "print(f'Accuracy: {round((totalPredictions-num_false_predictions2) / totalPredictions2 * 100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** CONCLUSION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This attempt to load the model on a new dataset (i.e. \"voice2.csv\") was unsuccessful.  After much testing  and review, it was incontravertible that the culprit of the failed model is the dataset itself, which was auto-generated with ChatGPT in order to simulate the instance of brand new data.  This experiment aimed to ascertain whether or not this neural network model was robust to new, auto-generated data--it appears strongly conclusive that unfortunately, it is not.  Without the ability to input data that is consistent, I am unable to observe how this model performs on new data; however, performance evaluation of the first model at the top of the notebook is powerful and effective as evidenced by its loss and accuracy scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
