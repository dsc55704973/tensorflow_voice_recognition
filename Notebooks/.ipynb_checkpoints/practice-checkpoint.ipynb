{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Neural Network: Gender Recognition by Voice and Speech Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for reviewing my Jupyter Notebook, which exhibits a neural network model I developed with Tensorflow.  The model is trained on a dataset featuring comprehensive parameters of the human voice (please review section below dedicated to describing the dataset).  Development of the nueral network was straight-forward given how lean the dataset actually is (3,168 records, 20 features) and how inherently robust neural network models are.  \n",
    "\n",
    "Essentially, I trained a model here that will predict the gender of a speaker given these 20 voice parameters.  The end result is a model that generated predictions with 98.23% accuracy, and only 14 wrong predictions!  Pretty remarkable.  The steps to execute this model are generalized as follows: \n",
    "###### Step 1: EDA\n",
    "###### Step 2: Pre-Processing\n",
    "###### Step 3: Model Development\n",
    "###### Step 4: Quantify the Trained Model\n",
    "###### Step 5: Make Predictions\n",
    "###### Step 6: Evaluate Test Results\n",
    "\n",
    "There really wasn't much to the EDA step, except that I just took a cursory look at the features.  In the pre-processing step, I used MinMaxScaler and LabelEncoder to scale the X features and to encode the y variable, and of course TrainTestSplit to get the training and test sets (33% default split).  Model development was also simple, as it only required initiating a sequential model, compiling it, and fitting the model to the categorical X training data with 60 epochs.  Quantifying the model simply involved computing loss and accuracy using evaluate().  In the Making Predictions step, I executed such predictions on scaled test dataset, and then converted the probabilities to class labels to view predictions alongside actuals.  The final step of evaluation entailed recomputing loss and accuracy manually by first computing how many false predictions were made, and finally taking a look at a confusion matrix using Scikit-Learn.\n",
    "\n",
    "The last thing I did was simulate saving and loading the model on new data.  For that, I attempted to leverage ChatGPT on generating a new dataset.  Loading the model on this dataset was unsuccessful, as may be predictable, as the fake dataset failed to capture real patterns that were consistent with the original dataset.  Nevertheless, a template now exists for loading in another dataset in order to test the model's effectiveness on new data.\n",
    "\n",
    "I am proud of my work here and am excited to continue to leverage the power of deep learning for other tasks!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Gender\n",
    "Gender Recognition by Voice and Speech Analysis\n",
    "\n",
    "This database was created to identify a voice as male or female, based upon acoustic properties of the voice and speech. The dataset consists of 3,168 recorded voice samples, collected from male and female speakers. The voice samples are pre-processed by acoustic analysis in R using the seewave and tuneR packages, with an analyzed frequency range of 0hz-280hz (human vocal range).\n",
    "\n",
    "## The Dataset\n",
    "The following acoustic properties of each voice are measured and included within the CSV:\n",
    "\n",
    "* meanfreq: mean frequency (in kHz)\n",
    "* sd: standard deviation of frequency\n",
    "* median: median frequency (in kHz)\n",
    "* Q25: first quantile (in kHz)\n",
    "* Q75: third quantile (in kHz)\n",
    "* IQR: interquantile range (in kHz)\n",
    "* skew: skewness (see note in specprop description)\n",
    "* kurt: kurtosis (see note in specprop description)\n",
    "* sp.ent: spectral entropy\n",
    "* sfm: spectral flatness\n",
    "* mode: mode frequency\n",
    "* centroid: frequency centroid (see specprop)\n",
    "* peakf: peak frequency (frequency with highest energy)\n",
    "* meanfun: average of fundamental frequency measured across acoustic signal\n",
    "* minfun: minimum fundamental frequency measured across acoustic signal\n",
    "* maxfun: maximum fundamental frequency measured across acoustic signal\n",
    "* meandom: average of dominant frequency measured across acoustic signal\n",
    "* mindom: minimum of dominant frequency measured across acoustic signal\n",
    "* maxdom: maximum of dominant frequency measured across acoustic signal\n",
    "* dfrange: range of dominant frequency measured across acoustic signal\n",
    "* modindx: modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range\n",
    "* label: male or female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt',\n",
       "       'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun',\n",
       "       'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice = pd.read_csv('../Resources/voice.csv')\n",
    "voice.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86a9e3212f200d21",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 20) (3168,)\n"
     ]
    }
   ],
   "source": [
    "# set features X and predictor y\n",
    "X = voice.drop(\"label\",axis =1)\n",
    "y = voice[\"label\"]\n",
    "\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711a82d9b32c83ff",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 500)\n",
    "\n",
    "# fit X TRAINING SET only with scaler; transform X TRAINING and X TEST sets\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# ENCODE Y sets\n",
    "# Step 1: Label-encode data set with LabelEncoder()\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_encoded_train = label_encoder.transform(y_train)\n",
    "y_encoded_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding using to_categorical()\n",
    "y_train_categorical = to_categorical(y_encoded_train)\n",
    "y_test_categorical = to_categorical(y_encoded_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create neural network model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 100, activation = 'relu', input_dim = 20))\n",
    "model.add(Dense(units = 100, activation = 'relu'))\n",
    "model.add(Dense(units=2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m2,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m202\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,402</span> (48.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,402\u001b[0m (48.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,402</span> (48.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,402\u001b[0m (48.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "75/75 - 0s - 5ms/step - accuracy: 0.7992 - loss: 0.4733\n",
      "Epoch 2/60\n",
      "75/75 - 0s - 432us/step - accuracy: 0.9386 - loss: 0.2113\n",
      "Epoch 3/60\n",
      "75/75 - 0s - 481us/step - accuracy: 0.9613 - loss: 0.1218\n",
      "Epoch 4/60\n",
      "75/75 - 0s - 481us/step - accuracy: 0.9697 - loss: 0.0962\n",
      "Epoch 5/60\n",
      "75/75 - 0s - 485us/step - accuracy: 0.9726 - loss: 0.0864\n",
      "Epoch 6/60\n",
      "75/75 - 0s - 480us/step - accuracy: 0.9726 - loss: 0.0871\n",
      "Epoch 7/60\n",
      "75/75 - 0s - 490us/step - accuracy: 0.9747 - loss: 0.0772\n",
      "Epoch 8/60\n",
      "75/75 - 0s - 469us/step - accuracy: 0.9722 - loss: 0.0825\n",
      "Epoch 9/60\n",
      "75/75 - 0s - 467us/step - accuracy: 0.9747 - loss: 0.0816\n",
      "Epoch 10/60\n",
      "75/75 - 0s - 469us/step - accuracy: 0.9752 - loss: 0.0755\n",
      "Epoch 11/60\n",
      "75/75 - 0s - 474us/step - accuracy: 0.9773 - loss: 0.0750\n",
      "Epoch 12/60\n",
      "75/75 - 0s - 479us/step - accuracy: 0.9743 - loss: 0.0738\n",
      "Epoch 13/60\n",
      "75/75 - 0s - 457us/step - accuracy: 0.9769 - loss: 0.0748\n",
      "Epoch 14/60\n",
      "75/75 - 0s - 503us/step - accuracy: 0.9785 - loss: 0.0707\n",
      "Epoch 15/60\n",
      "75/75 - 0s - 482us/step - accuracy: 0.9769 - loss: 0.0683\n",
      "Epoch 16/60\n",
      "75/75 - 0s - 489us/step - accuracy: 0.9785 - loss: 0.0703\n",
      "Epoch 17/60\n",
      "75/75 - 0s - 483us/step - accuracy: 0.9802 - loss: 0.0646\n",
      "Epoch 18/60\n",
      "75/75 - 0s - 464us/step - accuracy: 0.9777 - loss: 0.0661\n",
      "Epoch 19/60\n",
      "75/75 - 0s - 492us/step - accuracy: 0.9794 - loss: 0.0668\n",
      "Epoch 20/60\n",
      "75/75 - 0s - 494us/step - accuracy: 0.9769 - loss: 0.0699\n",
      "Epoch 21/60\n",
      "75/75 - 0s - 483us/step - accuracy: 0.9781 - loss: 0.0633\n",
      "Epoch 22/60\n",
      "75/75 - 0s - 491us/step - accuracy: 0.9794 - loss: 0.0611\n",
      "Epoch 23/60\n",
      "75/75 - 0s - 485us/step - accuracy: 0.9819 - loss: 0.0599\n",
      "Epoch 24/60\n",
      "75/75 - 0s - 482us/step - accuracy: 0.9798 - loss: 0.0613\n",
      "Epoch 25/60\n",
      "75/75 - 0s - 494us/step - accuracy: 0.9781 - loss: 0.0638\n",
      "Epoch 26/60\n",
      "75/75 - 0s - 481us/step - accuracy: 0.9806 - loss: 0.0579\n",
      "Epoch 27/60\n",
      "75/75 - 0s - 488us/step - accuracy: 0.9811 - loss: 0.0567\n",
      "Epoch 28/60\n",
      "75/75 - 0s - 492us/step - accuracy: 0.9806 - loss: 0.0593\n",
      "Epoch 29/60\n",
      "75/75 - 0s - 471us/step - accuracy: 0.9773 - loss: 0.0670\n",
      "Epoch 30/60\n",
      "75/75 - 0s - 459us/step - accuracy: 0.9798 - loss: 0.0569\n",
      "Epoch 31/60\n",
      "75/75 - 0s - 474us/step - accuracy: 0.9832 - loss: 0.0536\n",
      "Epoch 32/60\n",
      "75/75 - 0s - 472us/step - accuracy: 0.9802 - loss: 0.0561\n",
      "Epoch 33/60\n",
      "75/75 - 0s - 476us/step - accuracy: 0.9806 - loss: 0.0549\n",
      "Epoch 34/60\n",
      "75/75 - 0s - 471us/step - accuracy: 0.9823 - loss: 0.0569\n",
      "Epoch 35/60\n",
      "75/75 - 0s - 477us/step - accuracy: 0.9823 - loss: 0.0551\n",
      "Epoch 36/60\n",
      "75/75 - 0s - 458us/step - accuracy: 0.9790 - loss: 0.0549\n",
      "Epoch 37/60\n",
      "75/75 - 0s - 487us/step - accuracy: 0.9819 - loss: 0.0505\n",
      "Epoch 38/60\n",
      "75/75 - 0s - 481us/step - accuracy: 0.9819 - loss: 0.0525\n",
      "Epoch 39/60\n",
      "75/75 - 0s - 485us/step - accuracy: 0.9806 - loss: 0.0603\n",
      "Epoch 40/60\n",
      "75/75 - 0s - 476us/step - accuracy: 0.9827 - loss: 0.0545\n",
      "Epoch 41/60\n",
      "75/75 - 0s - 464us/step - accuracy: 0.9827 - loss: 0.0503\n",
      "Epoch 42/60\n",
      "75/75 - 0s - 489us/step - accuracy: 0.9811 - loss: 0.0524\n",
      "Epoch 43/60\n",
      "75/75 - 0s - 490us/step - accuracy: 0.9832 - loss: 0.0488\n",
      "Epoch 44/60\n",
      "75/75 - 0s - 484us/step - accuracy: 0.9747 - loss: 0.0593\n",
      "Epoch 45/60\n",
      "75/75 - 0s - 490us/step - accuracy: 0.9823 - loss: 0.0481\n",
      "Epoch 46/60\n",
      "75/75 - 0s - 483us/step - accuracy: 0.9844 - loss: 0.0451\n",
      "Epoch 47/60\n",
      "75/75 - 0s - 501us/step - accuracy: 0.9844 - loss: 0.0457\n",
      "Epoch 48/60\n",
      "75/75 - 0s - 470us/step - accuracy: 0.9836 - loss: 0.0460\n",
      "Epoch 49/60\n",
      "75/75 - 0s - 466us/step - accuracy: 0.9836 - loss: 0.0437\n",
      "Epoch 50/60\n",
      "75/75 - 0s - 462us/step - accuracy: 0.9848 - loss: 0.0459\n",
      "Epoch 51/60\n",
      "75/75 - 0s - 455us/step - accuracy: 0.9840 - loss: 0.0455\n",
      "Epoch 52/60\n",
      "75/75 - 0s - 467us/step - accuracy: 0.9853 - loss: 0.0429\n",
      "Epoch 53/60\n",
      "75/75 - 0s - 469us/step - accuracy: 0.9853 - loss: 0.0440\n",
      "Epoch 54/60\n",
      "75/75 - 0s - 463us/step - accuracy: 0.9844 - loss: 0.0455\n",
      "Epoch 55/60\n",
      "75/75 - 0s - 476us/step - accuracy: 0.9811 - loss: 0.0502\n",
      "Epoch 56/60\n",
      "75/75 - 0s - 439us/step - accuracy: 0.9836 - loss: 0.0420\n",
      "Epoch 57/60\n",
      "75/75 - 0s - 435us/step - accuracy: 0.9844 - loss: 0.0437\n",
      "Epoch 58/60\n",
      "75/75 - 0s - 437us/step - accuracy: 0.9840 - loss: 0.0443\n",
      "Epoch 59/60\n",
      "75/75 - 0s - 431us/step - accuracy: 0.9853 - loss: 0.0416\n",
      "Epoch 60/60\n",
      "75/75 - 0s - 443us/step - accuracy: 0.9861 - loss: 0.0387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3138b1dd0>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train_scaled,\n",
    "          y_train_categorical,\n",
    "          epochs=60,\n",
    "          shuffle=2,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - 2ms/step - accuracy: 0.9823 - loss: 0.0602\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled,\n",
    "    y_test_categorical,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f97eb3e97245187b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step\n"
     ]
    }
   ],
   "source": [
    "# predictions on X_test_scaled\n",
    "predictions = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probabilities to class labels\n",
    "encoded_predictions = predictions.argmax(axis=-1)\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['female' 'female' 'female' 'female' 'female' 'female' 'male' 'female'\n",
      " 'male' 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'female'\n",
      " 'female' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'female' 'female'\n",
      " 'male' 'female' 'male' 'male' 'female' 'female' 'male' 'female' 'male'\n",
      " 'male' 'male' 'female' 'female' 'male' 'female' 'female' 'female' 'male'\n",
      " 'male' 'female' 'female' 'female' 'female' 'male' 'female' 'male'\n",
      " 'female' 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'female'\n",
      " 'male' 'male' 'female' 'female' 'female' 'male' 'female' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'male' 'female' 'male' 'male' 'female'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'male' 'female'\n",
      " 'female' 'male' 'female' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'female' 'female' 'male' 'female' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'female' 'female' 'male' 'male'\n",
      " 'female' 'female' 'female' 'male' 'female' 'male' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'female' 'female' 'female' 'female'\n",
      " 'male' 'male' 'male' 'female' 'male' 'female' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'male' 'male'\n",
      " 'female' 'female' 'female' 'female' 'male' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male' 'male' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'female' 'male'\n",
      " 'female' 'male' 'female' 'female' 'female' 'male' 'male' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male' 'female' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'female' 'female' 'female' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'female' 'female' 'female' 'male'\n",
      " 'male' 'female' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'male' 'female' 'male' 'male' 'female' 'female' 'female'\n",
      " 'female' 'male' 'male' 'male' 'male' 'male' 'female' 'female' 'female'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'female'\n",
      " 'female' 'male' 'female' 'female' 'male' 'female' 'female' 'female'\n",
      " 'male' 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'female' 'male' 'female' 'male' 'female' 'female' 'female' 'male'\n",
      " 'female' 'male' 'female' 'female' 'male' 'male' 'male' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'male' 'female' 'female' 'male' 'male'\n",
      " 'male' 'male' 'female' 'male' 'male' 'male' 'female' 'male' 'male'\n",
      " 'female' 'female' 'female' 'male' 'male' 'female' 'female' 'female'\n",
      " 'male' 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'female' 'female'\n",
      " 'male' 'male' 'male' 'female' 'female' 'male' 'female' 'female' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'female' 'male'\n",
      " 'male' 'female' 'male' 'male' 'female' 'female' 'male' 'female' 'male'\n",
      " 'male' 'male' 'female' 'male' 'male' 'female' 'female' 'female' 'female'\n",
      " 'male' 'male' 'female' 'female' 'male' 'male' 'female' 'male' 'female'\n",
      " 'female' 'male' 'female' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'male' 'female' 'male' 'male' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'female' 'male' 'male'\n",
      " 'male' 'male' 'female' 'female' 'male' 'female' 'female' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'male' 'female' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'female'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'female' 'male' 'male' 'female' 'male' 'female' 'female' 'male'\n",
      " 'male' 'female' 'female' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'female' 'male' 'male' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'male' 'female' 'female' 'male' 'female' 'male' 'male'\n",
      " 'female' 'male' 'male' 'male' 'male' 'female' 'female' 'female' 'male'\n",
      " 'male' 'female' 'female' 'male' 'female' 'male' 'female' 'female' 'male'\n",
      " 'male' 'female' 'female' 'male' 'female' 'female' 'male' 'female'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'male' 'female' 'male' 'female' 'female'\n",
      " 'male' 'female' 'female' 'female' 'male' 'female' 'male' 'female'\n",
      " 'female' 'male' 'female' 'female' 'male' 'female' 'female' 'female'\n",
      " 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'female' 'female' 'male' 'male' 'male'\n",
      " 'male' 'female' 'female' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'female'\n",
      " 'male' 'male' 'male' 'male' 'female' 'female' 'female' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'female' 'male'\n",
      " 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'male'\n",
      " 'male' 'male' 'female' 'male' 'female' 'female' 'female' 'female'\n",
      " 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'female'\n",
      " 'female' 'female' 'male' 'female' 'male' 'female' 'male' 'female' 'male'\n",
      " 'male' 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'female' 'female'\n",
      " 'female' 'female' 'male' 'female' 'female' 'female' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'male' 'male' 'female' 'female' 'female' 'female' 'male'\n",
      " 'female' 'female' 'male' 'female' 'male' 'female' 'female' 'male' 'male'\n",
      " 'male' 'male' 'female' 'male' 'female' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'female' 'female' 'male'\n",
      " 'female' 'male' 'male' 'female' 'male' 'female' 'female' 'male' 'male'\n",
      " 'female' 'male' 'male']\n",
      "Actuals: ['female', 'female', 'female', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'male', 'female', 'male', 'female', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'female', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'female', 'male', 'male']\n"
     ]
    }
   ],
   "source": [
    "# print predictions vs. actuals\n",
    "print(f'Predictions: {prediction_labels}')\n",
    "print(f'Actuals: {list(y_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 false predictions out of 792 predictions ---> Counter({'male': 403, 'female': 389})\n",
      "Accuracy: 98.23%\n",
      "Check Accuracy: 98.22999999999999%\n"
     ]
    }
   ],
   "source": [
    "# loss and accuracy\n",
    "false_predictions = prediction_labels != y_test\n",
    "num_false_predictions = np.sum(false_predictions)\n",
    "totalPredictions = len(prediction_labels)\n",
    "\n",
    "print(f'{num_false_predictions} false predictions out of {totalPredictions} predictions ---> {Counter(prediction_labels)}')\n",
    "print(f'Accuracy: {round((totalPredictions-num_false_predictions) / totalPredictions * 100,2)}%')\n",
    "print(f'Check Accuracy: {round(model_accuracy,4)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1\n",
      " 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0\n",
      " 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0\n",
      " 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1\n",
      " 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 0\n",
      " 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0\n",
      " 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0\n",
      " 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1\n",
      " 1 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0\n",
      " 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0\n",
      " 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 1 0\n",
      " 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0\n",
      " 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0\n",
      " 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1]\n",
      "[0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1\n",
      " 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0\n",
      " 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0\n",
      " 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1\n",
      " 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0\n",
      " 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 0\n",
      " 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0\n",
      " 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1\n",
      " 1 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0\n",
      " 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0\n",
      " 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 1 0\n",
      " 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0\n",
      " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0\n",
      " 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_encoded_test,encoded_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(encoded_predictions)\n",
    "print(y_encoded_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"voice_gender_nn_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Dataset: Attempt to Execute Predictive Analytics on Alternate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in new dataset (labels randomized in new file)\n",
    "voice2 = pd.read_csv('../Resources/voice2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "X2 = voice2.drop(\"label\",axis =1)\n",
    "y2 = voice2[\"label\"]\n",
    "\n",
    "# train, test, split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2,random_state = 2)\n",
    "\n",
    "# fit X TRAINING SET only with scaler; transform X TRAINING and X TEST sets\n",
    "X_scaler2 = MinMaxScaler().fit(X_train2)\n",
    "X_train_scaled2 = X_scaler2.transform(X_train2)\n",
    "X_test_scaled2 = X_scaler2.transform(X_test2)\n",
    "\n",
    "# ENCODE Y sets\n",
    "# Step 1: Label-encode data set with LabelEncoder()\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train2)\n",
    "y_encoded_train2 = label_encoder.transform(y_train2)\n",
    "y_encoded_test2 = label_encoder.transform(y_test2)\n",
    "\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding using to_categorical()\n",
    "y_train_categorical2 = to_categorical(y_encoded_train2)\n",
    "y_test_categorical2 = to_categorical(y_encoded_test2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = load_model('voice_gender_nn_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step\n"
     ]
    }
   ],
   "source": [
    "# Attempt predictions\n",
    "predictions2 = model.predict(X_test_scaled2)\n",
    "encoded_predictions2 = predictions2.argmax(axis=-1)\n",
    "prediction_labels2 = label_encoder.inverse_transform(encoded_predictions2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 false predictions out of 792 predictions ---> Counter({'female': 425, 'male': 367})\n",
      "Accuracy: 49.62%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate \n",
    "\n",
    "false_predictions2 = prediction_labels2 != y_test2\n",
    "num_false_predictions2 = np.sum(false_predictions2)\n",
    "totalPredictions2 = len(prediction_labels2)\n",
    "\n",
    "print(f'{num_false_predictions2} false predictions out of {totalPredictions2} predictions ---> {Counter(prediction_labels2)}')\n",
    "print(f'Accuracy: {round((totalPredictions-num_false_predictions2) / totalPredictions2 * 100,2)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAIL (hypothesis: new dataset and unseen patterns are inconsistent with original dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to retrain new model on new data and retry predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m2,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m202\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,402</span> (48.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,402\u001b[0m (48.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,402</span> (48.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,402\u001b[0m (48.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - 3ms/step - accuracy: 0.5278 - loss: 0.7028\n"
     ]
    }
   ],
   "source": [
    "# Create neural network model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 100, activation = 'relu', input_dim = 20))\n",
    "model.add(Dense(units = 100, activation = 'relu'))\n",
    "model.add(Dense(units=2, activation = 'softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model_loss2, model_accuracy2 = model.evaluate(\n",
    "    X_test_scaled2,\n",
    "    y_test_categorical2,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "75/75 - 1s - 8ms/step - accuracy: 0.5067 - loss: 0.6963\n",
      "Epoch 2/60\n",
      "75/75 - 0s - 424us/step - accuracy: 0.5160 - loss: 0.6912\n",
      "Epoch 3/60\n",
      "75/75 - 0s - 440us/step - accuracy: 0.5332 - loss: 0.6896\n",
      "Epoch 4/60\n",
      "75/75 - 0s - 438us/step - accuracy: 0.5349 - loss: 0.6870\n",
      "Epoch 5/60\n",
      "75/75 - 0s - 450us/step - accuracy: 0.5543 - loss: 0.6857\n",
      "Epoch 6/60\n",
      "75/75 - 0s - 442us/step - accuracy: 0.5636 - loss: 0.6816\n",
      "Epoch 7/60\n",
      "75/75 - 0s - 445us/step - accuracy: 0.5648 - loss: 0.6798\n",
      "Epoch 8/60\n",
      "75/75 - 0s - 453us/step - accuracy: 0.5694 - loss: 0.6770\n",
      "Epoch 9/60\n",
      "75/75 - 0s - 445us/step - accuracy: 0.5787 - loss: 0.6702\n",
      "Epoch 10/60\n",
      "75/75 - 0s - 452us/step - accuracy: 0.6044 - loss: 0.6644\n",
      "Epoch 11/60\n",
      "75/75 - 0s - 448us/step - accuracy: 0.5955 - loss: 0.6602\n",
      "Epoch 12/60\n",
      "75/75 - 0s - 475us/step - accuracy: 0.6136 - loss: 0.6572\n",
      "Epoch 13/60\n",
      "75/75 - 0s - 479us/step - accuracy: 0.6317 - loss: 0.6487\n",
      "Epoch 14/60\n",
      "75/75 - 0s - 508us/step - accuracy: 0.6292 - loss: 0.6447\n",
      "Epoch 15/60\n",
      "75/75 - 0s - 504us/step - accuracy: 0.6385 - loss: 0.6354\n",
      "Epoch 16/60\n",
      "75/75 - 0s - 483us/step - accuracy: 0.6435 - loss: 0.6317\n",
      "Epoch 17/60\n",
      "75/75 - 0s - 528us/step - accuracy: 0.6549 - loss: 0.6195\n",
      "Epoch 18/60\n",
      "75/75 - 0s - 537us/step - accuracy: 0.6747 - loss: 0.6077\n",
      "Epoch 19/60\n",
      "75/75 - 0s - 504us/step - accuracy: 0.6776 - loss: 0.6009\n",
      "Epoch 20/60\n",
      "75/75 - 0s - 510us/step - accuracy: 0.6768 - loss: 0.5941\n",
      "Epoch 21/60\n",
      "75/75 - 0s - 504us/step - accuracy: 0.7003 - loss: 0.5833\n",
      "Epoch 22/60\n",
      "75/75 - 0s - 491us/step - accuracy: 0.7176 - loss: 0.5692\n",
      "Epoch 23/60\n",
      "75/75 - 0s - 510us/step - accuracy: 0.7214 - loss: 0.5631\n",
      "Epoch 24/60\n",
      "75/75 - 0s - 474us/step - accuracy: 0.7214 - loss: 0.5538\n",
      "Epoch 25/60\n",
      "75/75 - 0s - 546us/step - accuracy: 0.7285 - loss: 0.5459\n",
      "Epoch 26/60\n",
      "75/75 - 0s - 519us/step - accuracy: 0.7466 - loss: 0.5356\n",
      "Epoch 27/60\n",
      "75/75 - 0s - 520us/step - accuracy: 0.7475 - loss: 0.5321\n",
      "Epoch 28/60\n",
      "75/75 - 0s - 510us/step - accuracy: 0.7753 - loss: 0.5104\n",
      "Epoch 29/60\n",
      "75/75 - 0s - 515us/step - accuracy: 0.7698 - loss: 0.5070\n",
      "Epoch 30/60\n",
      "75/75 - 0s - 517us/step - accuracy: 0.7757 - loss: 0.4899\n",
      "Epoch 31/60\n",
      "75/75 - 0s - 512us/step - accuracy: 0.7900 - loss: 0.4808\n",
      "Epoch 32/60\n",
      "75/75 - 0s - 525us/step - accuracy: 0.7921 - loss: 0.4712\n",
      "Epoch 33/60\n",
      "75/75 - 0s - 511us/step - accuracy: 0.8068 - loss: 0.4598\n",
      "Epoch 34/60\n",
      "75/75 - 0s - 519us/step - accuracy: 0.8098 - loss: 0.4521\n",
      "Epoch 35/60\n",
      "75/75 - 0s - 512us/step - accuracy: 0.8178 - loss: 0.4393\n",
      "Epoch 36/60\n",
      "75/75 - 0s - 498us/step - accuracy: 0.8274 - loss: 0.4227\n",
      "Epoch 37/60\n",
      "75/75 - 0s - 500us/step - accuracy: 0.8308 - loss: 0.4155\n",
      "Epoch 38/60\n",
      "75/75 - 0s - 495us/step - accuracy: 0.8413 - loss: 0.4095\n",
      "Epoch 39/60\n",
      "75/75 - 0s - 491us/step - accuracy: 0.8447 - loss: 0.3921\n",
      "Epoch 40/60\n",
      "75/75 - 0s - 533us/step - accuracy: 0.8342 - loss: 0.3954\n",
      "Epoch 41/60\n",
      "75/75 - 0s - 466us/step - accuracy: 0.8447 - loss: 0.3830\n",
      "Epoch 42/60\n",
      "75/75 - 0s - 453us/step - accuracy: 0.8620 - loss: 0.3670\n",
      "Epoch 43/60\n",
      "75/75 - 0s - 459us/step - accuracy: 0.8628 - loss: 0.3609\n",
      "Epoch 44/60\n",
      "75/75 - 0s - 454us/step - accuracy: 0.8716 - loss: 0.3486\n",
      "Epoch 45/60\n",
      "75/75 - 0s - 477us/step - accuracy: 0.8771 - loss: 0.3348\n",
      "Epoch 46/60\n",
      "75/75 - 0s - 456us/step - accuracy: 0.8826 - loss: 0.3318\n",
      "Epoch 47/60\n",
      "75/75 - 0s - 471us/step - accuracy: 0.8754 - loss: 0.3277\n",
      "Epoch 48/60\n",
      "75/75 - 0s - 491us/step - accuracy: 0.8796 - loss: 0.3191\n",
      "Epoch 49/60\n",
      "75/75 - 0s - 510us/step - accuracy: 0.8927 - loss: 0.3055\n",
      "Epoch 50/60\n",
      "75/75 - 0s - 521us/step - accuracy: 0.8977 - loss: 0.3006\n",
      "Epoch 51/60\n",
      "75/75 - 0s - 519us/step - accuracy: 0.9028 - loss: 0.2884\n",
      "Epoch 52/60\n",
      "75/75 - 0s - 498us/step - accuracy: 0.9146 - loss: 0.2717\n",
      "Epoch 53/60\n",
      "75/75 - 0s - 545us/step - accuracy: 0.9129 - loss: 0.2742\n",
      "Epoch 54/60\n",
      "75/75 - 0s - 485us/step - accuracy: 0.9171 - loss: 0.2669\n",
      "Epoch 55/60\n",
      "75/75 - 0s - 492us/step - accuracy: 0.9108 - loss: 0.2648\n",
      "Epoch 56/60\n",
      "75/75 - 0s - 467us/step - accuracy: 0.9280 - loss: 0.2441\n",
      "Epoch 57/60\n",
      "75/75 - 0s - 495us/step - accuracy: 0.9339 - loss: 0.2370\n",
      "Epoch 58/60\n",
      "75/75 - 0s - 495us/step - accuracy: 0.9348 - loss: 0.2312\n",
      "Epoch 59/60\n",
      "75/75 - 0s - 581us/step - accuracy: 0.9348 - loss: 0.2259\n",
      "Epoch 60/60\n",
      "75/75 - 0s - 477us/step - accuracy: 0.9461 - loss: 0.2077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3143b6350>"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train_scaled2,\n",
    "          y_train_categorical2,\n",
    "          epochs=60,\n",
    "          shuffle=2,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step\n"
     ]
    }
   ],
   "source": [
    "# Attempt predictions\n",
    "predictions2 = model.predict(X_test_scaled2)\n",
    "encoded_predictions2 = predictions2.argmax(axis=-1)\n",
    "prediction_labels2 = label_encoder.inverse_transform(encoded_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 false predictions out of 792 predictions ---> Counter({'male': 419, 'female': 373})\n",
      "Accuracy: 50.63%\n"
     ]
    }
   ],
   "source": [
    "false_predictions2 = prediction_labels2 != y_test2\n",
    "num_false_predictions2 = np.sum(false_predictions2)\n",
    "totalPredictions2 = len(prediction_labels2)\n",
    "\n",
    "print(f'{num_false_predictions2} false predictions out of {totalPredictions2} predictions ---> {Counter(prediction_labels2)}')\n",
    "print(f'Accuracy: {round((totalPredictions-num_false_predictions2) / totalPredictions2 * 100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** CONCLUSION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This attempt to load the model on a new dataset (i.e. \"voice2.csv\") was unsuccessful.  After much testing  and review, it was incontravertible that the culprit of the failed model is the dataset itself, which was auto-generated with ChatGPT in order to simulate the instance of brand new data.  This experiment aimed to ascertain whether or not this neural network model was robust to new, auto-generated data--it appears strongly conclusive that unfortunately, it is not.  Without the ability to input data that is consistent, I am unable to observe how this model performs on new data; however, performance evaluation of the first model at the top of the notebook is powerful and effective as evidenced by its loss and accuracy scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
